{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 해외뉴스번역"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 키워드 분석\n",
    "#### 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl #그래프\n",
    "import re #특수문자 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 샘플 데이터 가져오기\n",
    "> 10112017의 cnn기사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>KEYWORDS</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['despair', 'rides', 'vegetables', 'york', 'we...</td>\n",
       "      <td>The opinions expressed in this commentary are ...</td>\n",
       "      <td>Story highlights Kenneth Podziba: Cycling offe...</td>\n",
       "      <td>Why we'll never stop biking</td>\n",
       "      <td>https://www.cnn.com/2017/11/01/opinions/terror...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['david', 'obamas', 'sasha', 'obama', 'axelrod...</td>\n",
       "      <td>Photos: Presidential inaugurations since 1789 ...</td>\n",
       "      <td>David Axelrod is CNN's senior political commen...</td>\n",
       "      <td>David Axelrod: Obama's legacy can't be erased</td>\n",
       "      <td>https://www.cnn.com/2017/01/20/opinions/david-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['temperatures', 'weekend', 'night', 'degrees'...</td>\n",
       "      <td>The National Weather Service had issued a wind...</td>\n",
       "      <td>Story highlights Wind advisory issued for Mass...</td>\n",
       "      <td>Cold, windy weather to blast Northeast this we...</td>\n",
       "      <td>https://www.cnn.com/2017/11/09/us/cold-weather...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           KEYWORDS  \\\n",
       "0           0  ['despair', 'rides', 'vegetables', 'york', 'we...   \n",
       "1           1  ['david', 'obamas', 'sasha', 'obama', 'axelrod...   \n",
       "2           2  ['temperatures', 'weekend', 'night', 'degrees'...   \n",
       "\n",
       "                                             SUMMARY  \\\n",
       "0  The opinions expressed in this commentary are ...   \n",
       "1  Photos: Presidential inaugurations since 1789 ...   \n",
       "2  The National Weather Service had issued a wind...   \n",
       "\n",
       "                                                TEXT  \\\n",
       "0  Story highlights Kenneth Podziba: Cycling offe...   \n",
       "1  David Axelrod is CNN's senior political commen...   \n",
       "2  Story highlights Wind advisory issued for Mass...   \n",
       "\n",
       "                                               TITLE  \\\n",
       "0                        Why we'll never stop biking   \n",
       "1      David Axelrod: Obama's legacy can't be erased   \n",
       "2  Cold, windy weather to blast Northeast this we...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.cnn.com/2017/11/01/opinions/terror...  \n",
       "1  https://www.cnn.com/2017/01/20/opinions/david-...  \n",
       "2  https://www.cnn.com/2017/11/09/us/cold-weather...  "
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_sample = pd.read_csv('./articles/Nov2017/csvdataset/10112017/cnn.csv')\n",
    "art_sample.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 키워드를 무슨 근거로 뽑은 건지 모르겠다 - 출처 분석\n",
    "> sample data에서 첫번째 기사 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keyword 분석을 위한 keyword data 미리보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['despair', 'rides', 'vegetables', 'york', 'wells', 'ride', 'riding', 'really', 'bicycle', 'bike', 'stop', 'biking']\""
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_data = art_sample['KEYWORDS'][0]\n",
    "key_data\n",
    "#type(key_data) ##pandas의 Series형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 샘플 데이터 전처리\n",
    "##### 특수문자 제거하기\n",
    ">##### 특수문자 제거를 위해 사용한 ftn\n",
    "- `re.sub('[제거할 문자]','대체',data)`\n",
    "- `list.replace('바꿀문자','대체')`\n",
    ">##### 단어 단위로 쪼개기\n",
    "- `list.split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = re.sub(\"['',-.]\",'',key_data) ##쓸데없는 문자 제거\n",
    "keyword = keyword.replace('[','').replace(']','').split(' ')\n",
    "\n",
    "summary_sp = re.sub('[.\\():,\"\"-/]',' ',art_sample['SUMMARY'][0])\n",
    "summary_sp = summary_sp.replace('\\n','').split(' ')\n",
    "\n",
    "title_sp = art_sample['TITLE'][0].split(' ')\n",
    "\n",
    "text_sp = re.sub('[.\\():,\"\"-/]',' ',art_sample['TEXT'][0])\n",
    "text_sp = text_sp.replace('\\n','').split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 대소문자 구별 없애기\n",
    "- 모두 소문자로 전처리    `list.lower()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_sp = list(map(str.lower,summary_sp))\n",
    "title_sp = list(map(str.lower,title_sp))\n",
    "text_sp = list(map(str.lower,text_sp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data 정리하기\n",
    "- 샘플 데이터에서 keyword로 분류된 단어가 각각 summary, title, text에 등장하는지의 여부를 논리연산자로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>despair</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rides</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vegetables</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>york</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wells</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ride</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>riding</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>really</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bicycle</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bike</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stop</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>biking</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  summary  title   text\n",
       "0      despair     True  False   True\n",
       "1        rides     True  False   True\n",
       "2   vegetables    False  False   True\n",
       "3         york     True  False   True\n",
       "4        wells     True  False   True\n",
       "5         ride    False  False   True\n",
       "6       riding     True  False   True\n",
       "7       really    False  False   True\n",
       "8      bicycle     True  False   True\n",
       "9         bike     True  False   True\n",
       "10        stop    False   True  False\n",
       "11      biking    False   True  False"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_0 = pd.DataFrame({'word':keyword})\n",
    "sample_0 = sample_0.assign(summary = sample_0['word'].isin(summary_sp), ## summary에 등장하는지\n",
    "               title = sample_0['word'].isin(title_sp), ## title에 등장하는지\n",
    "               text = sample_0['word'].isin(text_sp)) ## text에 등장하는지\n",
    "sample_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **keyword라고 해서 꼭 원문(text)에 등장한 것은 아니다.**\n",
    "- text에만 등장한 경우\n",
    "- summary와 text에 등장한 경우\n",
    "- title에만 등장한 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특수문자 제거한 TEXT(기사 원문) word 빈도분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 단어 출현 횟수를 저장하기 위한 리스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_fre = list()\n",
    "\n",
    "for i in range(len(text_sp)):\n",
    "    text_fre.append(text_sp.count(text_sp[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 단어와 출현 빈도를 포함한 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>fre</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bike</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>despair</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>bicycle</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>york</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>vegetables</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>ride</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>really</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>wells</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>riding</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>rides</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  fre  keyword\n",
       "36         bike    4     True\n",
       "111     despair    4     True\n",
       "106     bicycle    3     True\n",
       "49         york    3     True\n",
       "345  vegetables    2     True\n",
       "210        ride    2     True\n",
       "316      really    2     True\n",
       "95        wells    2     True\n",
       "34       riding    2     True\n",
       "364       rides    2     True"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sample_2 = pd.DataFrame({'word':list(map(str.lower,text_sp)),'fre':text_fre}).drop_duplicates().sort_values('fre',ascending=False)\n",
    "## 중복제거 ## fre값 기준 내림차순 정렬\n",
    "\n",
    "text_sample_2['keyword'] = text_sample_2['word'].isin(keyword) ## text의 단어가 keyword 리스트에도 포함되는지 여부\n",
    "\n",
    "text_sample_2 = text_sample_2[text_sample_2['keyword']==True] ## 적어도 2번 이상 출현한 단어 & keyword 분류에 포함되는 단어\n",
    "\n",
    "text_sample_2 ## keyword의 단어가 text(원문)에 몇번 등장하는지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **keyword라고 해서 text에 자주 등장하지 않는다**\n",
    "- keyword임에도 text에서 1번 등장한 단어가 존재(bike, riding)\n",
    "- text에 등장하지 않는(title에만 등장) 경우에는 어떤 기준으로 keyword로 분류하는지?\n",
    "\n",
    "- 같은 단어를 다른 방식으로 표현하는 경우(rides - ride - riding): 형태는 다르지만 같은 의미\n",
    "- 비슷한 의미의 다른 형태(bike - bicycle - biking)\n",
    "\n",
    "**=> 어떻게 취합할 것인지**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text 빈도분석과 keyword 출처분석 결과 비교하기 (작업중)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-591-579e8b194d65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#result = pd.concat([sample_0, text_sample_3], axis = 1, join = 'outer',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                  \u001b[1;31m# keys = 'word')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msample_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtext_sample_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indexed_same\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m             raise ValueError(\"Can only compare identically-labeled \"\n\u001b[0m\u001b[0;32m   1677\u001b[0m                              \"Series objects\")\n\u001b[0;32m   1678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "#text_sample_3 = text_sample_2.iloc[:,0:2]\n",
    "#result = pd.concat([sample_0, text_sample_3], axis = 1, join = 'outer',\n",
    "                 # keys = 'word')\n",
    "sample_0['word'] == text_sample_2['word']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 키워드 분석 - 전체 데이터 적용 (작업중)\n",
    "#### 데이터 전처리 모듈 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    x = pd.read_csv(path)\n",
    "    #x_shape_0 = x.shape\n",
    "    #x = x.dropna(axis = 0, how = 'any') # 하나라도 결측치가 있는 row는 삭제\n",
    "    #print('삭제된 데이터: ',x_shape_0[0] - x.shape[0])\n",
    "    \n",
    "    # 초기 array 지정\n",
    "    keyword = re.sub(\"[':/\\',-.]\",'',x['KEYWORDS'][0]).replace('[','').replace(']','').split(' ')\n",
    "    keyword = list(map(str.lower,keyword))\n",
    "    summary = re.sub(\"[':/',-.]\",\"\",str(x['SUMMARY'][0])).replace('\\n','').split(' ')\n",
    "    summary = list(map(str.lower,summary))\n",
    "    title = re.sub(\"[':/\\',-.]\",'',x['TITLE'][0]).replace(\"'\",\"\").replace('\"','').split(' ')\n",
    "    title = list(map(str.lower,title))\n",
    "    text = re.sub(\"['':/,-.]\",'',str(x['TEXT'][0])).replace('\\n','').split(' ')\n",
    "    text = list(map(str.lower,text))\n",
    "    \n",
    "    ans_0 = np.array([[keyword,summary,title,text]])\n",
    "    \n",
    "    # 나머지 data 추가\n",
    "    for i in range(1,x.shape[0]):\n",
    "        keyword = re.sub(\"[':/\\',-.]\",'',x['KEYWORDS'][i]).replace('[','').replace(']','').split(' ')\n",
    "        keyword = list(map(str.lower,keyword))\n",
    "        summary = re.sub(\"[':/',-.]\",\"\",str(x['SUMMARY'][i])).replace('\\n','').split(' ')\n",
    "        summary = list(map(str.lower,summary))\n",
    "        title = re.sub(\"['',:/\\-.]\",'',x['TITLE'][i]).replace(\"'\",\"\").replace('\"','').split(' ')\n",
    "        title = list(map(str.lower,title))\n",
    "        text = re.sub(\"['',-:/.]\",'',str(x['TEXT'][i])).replace('\\n','').split(' ')\n",
    "        text = list(map(str.lower,text))\n",
    "        \n",
    "        ans_t = np.array([[keyword,summary,title,text]])\n",
    "        if ans_t.shape == (1,4):\n",
    "            ans = np.append(ans_0,ans_t,axis = 0)\n",
    "            ans_0 = ans\n",
    "        \n",
    "    print(' 전처리 완료 데이터: ',ans.shape[0],'개','\\n','전처리 과정에서 삭제된 데이터: ',x.shape[0] - ans.shape[0],'개')\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 전처리 완료 데이터:  350 개 \n",
      " 전처리 과정에서 삭제된 데이터:  1 개\n"
     ]
    }
   ],
   "source": [
    "s = preprocess('./articles/Nov2017/Nov2017/csvdataset/11082017/foxnews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keyword 출처를 나타내는 bool형 array 생성하기 (작업중)***여기서부터***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isin_keyword(x):\n",
    "    n = x[0].max()\n",
    "    ans_0 = np.array([[1,4,]])\n",
    "    print(ans_0.shape,ans_0[[0]])\n",
    "    \n",
    "    for i in range(1, x.shape[0]):\n",
    "        key = pd.Series(x[i,0])\n",
    "        summ = pd.Series(x[i,1])\n",
    "        tt = pd.Series(x[i,2])\n",
    "        txt = pd.Series(x[i,3])\n",
    "        \n",
    "        k_summary = key.isin(summ)\n",
    "        k_title = key.isin(tt)\n",
    "        k_text = key.isin(txt)\n",
    "        \n",
    "        ans_t = np.array([[key,k_summary,k_title,k_text]])\n",
    "        print(ans_t.shape)\n",
    "        ans = np.append(ans_0,ans_t,axis = 0)\n",
    "        ans_0 = ans\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-565-72da11642a6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misin_keyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-564-70dc05526892>\u001b[0m in \u001b[0;36misin_keyword\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0misin_keyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mans_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mans_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "s_b = isin_keyword(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
